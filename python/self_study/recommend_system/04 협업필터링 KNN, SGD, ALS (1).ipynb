{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 협업필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 협업필터링 개요\n",
    "\n",
    "1) 정의 : 사용자의 구매 패턴이나 평점을 가지고 다른 사람들의 구매 패턴, 평점을 통해 추천\n",
    "\n",
    "2) 종류 : 최근접 이웃 기반 / 잠재 요인 기반\n",
    "\n",
    "3) Neighborhood based method(이웃 기반)\n",
    "    - 정의 : 메모리 기반 알고리즘.\n",
    "    - 알고리즘 : \n",
    "        - User-based collaborative filtering : 사용자의 구매패턴(평점)과 유사한 사용자를 찾아서 추천리스트 생성\n",
    "        - Item-based collaborative filtering : 특정 사용자가 준 점수간의 유사한 상품을 찾아서 추천 리스트 생성\n",
    "    - KNN(K Nearest Neighbors) : 가장 근접한 K명의 Neighbors를 통해서 예측하는 방법\n",
    "        - 데이터(Explicit Feedback) : 유저가 자신의 선호도를 직접 표현한 데이터\n",
    "    - 장점 :\n",
    "        - 간단하고 직관적이다.\n",
    "        - 특정 item을 추천하는 이유를 정당화하기 쉽다. item기반 방법의 해석 가능성이 두드러진다.\n",
    "        - 추천 리스트에 새로운 item과 user가 추가되어도 상대적으로 안정적이다\n",
    "    - 단점 : \n",
    "        - user 기반 방법의 시간, 속도, 메모리가 많이 필요\n",
    "        - 희소성 때문에 제한된 범위가 있다\n",
    "            - John의 top-K만 관심이 있다.\n",
    "            - John과 비슷한 이웃 중 아무도 해리포터를 평가하지 않으면, 해리포터에 대한 예측을 제공할 수 없다\n",
    "\n",
    "4) Latent Factor Collaborative Filtering(잠재 요인 기반)\n",
    "    - 정의 : Rating Matrix에서 빈 공간을 채우기 위해 사용자와 상품을 잘 표현하는 차원(Latent Factor)을 찾는 방법.\n",
    "    - 원리 : 사용자의 잠재요인과 아이템의 잠재요인을 내적해서 평점 매트릭스를 계산\n",
    "        - Observed Only MF, Weighted MF, SVD\n",
    "    - SGD\n",
    "        - 정의 : 고유값 분해와 같은 행렬을 대각화 하는 방법\n",
    "        - 진행 과정 :\n",
    "            - User Latent와 Item Latent의 임의로 초기화\n",
    "            - Gradient Descent 진행\n",
    "            - 모든 평점에 대해서 반복(epoch = 1)\n",
    "            - 2~3의 과정을 10회 반복(epoch = 10)\n",
    "        - 장점 : 매우 유연한 모델로 다른 Loss Function을 사용할 수 있고, parallelized 가능\n",
    "        - 단점 : 수렴까지 속도가 매우 느리나 딥러닝을 통해 해결 가능\n",
    "    - ALS\n",
    "        - 정의 : 기존의 SGD가 두개의 행렬을 동시에 최적화 한다면, ALS는 두 행렬 중 하나를 고정시키고 다른 하나의 행렬을 순차적으로 반복하면서 최적화\n",
    "        - 알고리즘 :\n",
    "            - 초기 아이템, 사용자 행렬을 초기화\n",
    "            - 아이템 행렬을 고정하고 사용자 행렬을 최적화\n",
    "            - 사용자 행렬을 고정하고 아이템 행렬을 최적화\n",
    "            - 위의 2, 3 과정을 반복\n",
    "            \n",
    "5) 장점\n",
    "    - 도메인 지식이 필요하지 않음\n",
    "    - 사용자의 새롱누 흥미를 발견하기 좋음\n",
    "    - 시작단계의 모델로 선택하기 좋음(추가적인 문맥 정보 등이 필요하지 않음)\n",
    "    \n",
    "6) 단점\n",
    "    - 새로운 아이템에 대해서 다루기가 어려움\n",
    "    - side feature(고객의 개인정보, 아이템의 추가정보)를 포함시키기 어려움\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class MatrixFactorization() :\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose = False):\n",
    "        self._R = R #Rating Matrix\n",
    "        self._num_users, self._num_items = R.shape #사용자수, 아이템수\n",
    "        self._k = k # Latent space 의 크기(설정해주면 됨)\n",
    "        self._learning_rate = learning_rate #학습률\n",
    "        self._reg_param = reg_param #weight의 regularization 값\n",
    "        self._epochs = epochs #전체 학습 횟수\n",
    "        self._verbose = verbose # 학습 과정을 출력할지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(self, i, j):\n",
    "    return self._b + self._b_P[i] + self._b_Q[i] + self._P[i, :].got(self._Q[j: ,].T)\n",
    "    # User Latent space 와 Item latent space의 곱에 biases를 더함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "\n",
    "        # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
    "        # 참고: http://codepractice.tistory.com/90\n",
    "        xi, yi = self._R.nonzero()\n",
    "        predicted = self.get_complete_matrix()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(cost) / len(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(self, error, i, j):\n",
    "        \"\"\"\n",
    "        gradient of latent feature for GD\n",
    "\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param j: item index\n",
    "        :return: gradient of latent feature tuple\n",
    "        \"\"\"\n",
    "\n",
    "        dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
    "        dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
    "        return dp, dq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(self, i, j, rating):\n",
    "    #error term 계산\n",
    "    prediction = self.get_prediction(i, j)\n",
    "    error = rating - prediction\n",
    "    \n",
    "    # biases 업데이트\n",
    "    self._b_P[i] += self._learning_rate * (error - self._req_param * self._b_P[i])\n",
    "    self._b_Q[i] += self._learning_rate * (error - self._req_param * self._b_Q[i])\n",
    "    \n",
    "    # latent feature 업데이트\n",
    "    dp, dq = self.gradient(error, i, j)\n",
    "    self._P[i, :] += self._learning_rate * dp\n",
    "    self._Q[i, :] += self._learning_rate * dq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self) :\n",
    "    #p와 q라는 latent space 생성\n",
    "    self._P = np.random.normal(size = (self._num_users, self._k))\n",
    "    self._Q = np.random.normal(size = (self._num_items, self._k))\n",
    "    \n",
    "    #biases term 설정\n",
    "    self._b_P = np.zeros(self._num_users)\n",
    "    self._b_Q = np.zeros(self._num_items)\n",
    "    self._b = np.mean(self._R[np.where(self._R != 0)])\n",
    "    \n",
    "    # train\n",
    "    self._training_process = []\n",
    "    for epoch in range(self._epochs) :\n",
    "        xi, yi = self._R.nonzero() # 평점이 0이 아닌 것만 진행\n",
    "        for i, j in zip(xi, yi):\n",
    "            self.gradient_descent(i, j, self._R[i, j])\n",
    "        cost = self.cost()\n",
    "        self._training_process.append((epoch, cost))\n",
    "        \n",
    "        if self._verbose == True and ((epoch+ 1) % 10 == 0):\n",
    "            print(\"Iteration : %d ; cost = %.4f\" % (epoch +1, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization():\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : Update matrix latent weight and bias\n",
    "\n",
    "        참고: self._b에 대한 설명\n",
    "        - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
    "        - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
    "\n",
    "        :return: training_process\n",
    "        \"\"\"\n",
    "\n",
    "        # init latent features\n",
    "        self._P = np.random.normal(size=(self._num_users, self._k))\n",
    "        self._Q = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "        # init biases\n",
    "        self._b_P = np.zeros(self._num_users)\n",
    "        self._b_Q = np.zeros(self._num_items)\n",
    "        self._b = np.mean(self._R[np.where(self._R != 0)])\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        for epoch in range(self._epochs):\n",
    "\n",
    "            # rating이 존재하는 index를 기준으로 training\n",
    "            for i in range(self._num_users):\n",
    "                for j in range(self._num_items):\n",
    "                    if self._R[i, j] > 0:\n",
    "                        self.gradient_descent(i, j, self._R[i, j])\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "\n",
    "            # print status\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "\n",
    "        # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
    "        # 참고: http://codepractice.tistory.com/90\n",
    "        xi, yi = self._R.nonzero()\n",
    "        predicted = self.get_complete_matrix()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(cost) / len(xi)\n",
    "\n",
    "\n",
    "    def gradient(self, error, i, j):\n",
    "        \"\"\"\n",
    "        gradient of latent feature for GD\n",
    "\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param j: item index\n",
    "        :return: gradient of latent feature tuple\n",
    "        \"\"\"\n",
    "\n",
    "        dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
    "        dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
    "        return dp, dq\n",
    "\n",
    "\n",
    "    def gradient_descent(self, i, j, rating):\n",
    "        \"\"\"\n",
    "        graident descent function\n",
    "\n",
    "        :param i: user index of matrix\n",
    "        :param j: item index of matrix\n",
    "        :param rating: rating of (i,j)\n",
    "        \"\"\"\n",
    "\n",
    "        # get error\n",
    "        prediction = self.get_prediction(i, j)\n",
    "        error = rating - prediction\n",
    "\n",
    "        # update biases\n",
    "        self._b_P[i] += self._learning_rate * (error - self._reg_param * self._b_P[i])\n",
    "        self._b_Q[j] += self._learning_rate * (error - self._reg_param * self._b_Q[j])\n",
    "\n",
    "        # update latent feature\n",
    "        dp, dq = self.gradient(error, i, j)\n",
    "        self._P[i, :] += self._learning_rate * dp\n",
    "        self._Q[j, :] += self._learning_rate * dq\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\n",
    "\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        computer complete matrix PXQ + P.bias + Q.bias + global bias\n",
    "\n",
    "        - PXQ 행렬에 b_P[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
    "        - b_Q[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
    "        - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
    "\n",
    "        - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
    "\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[:, np.newaxis] + self._b_Q[np.newaxis:, ] + self._P.dot(self._Q.T)\n",
    "\n",
    "\n",
    "    def print_results(self):\n",
    "        \"\"\"\n",
    "        print fit results\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"User Latent P:\")\n",
    "        print(self._P)\n",
    "        print(\"Item Latent Q:\")\n",
    "        print(self._Q.T)\n",
    "        print(\"P x Q:\")\n",
    "        print(self._P.dot(self._Q.T))\n",
    "        print(\"bias:\")\n",
    "        print(self._b)\n",
    "        print(\"User Latent bias:\")\n",
    "        print(self._b_P)\n",
    "        print(\"Item Latent bias:\")\n",
    "        print(self._b_Q)\n",
    "        print(\"Final R matrix:\")\n",
    "        print(self.get_complete_matrix())\n",
    "        print(\"Final RMSE:\")\n",
    "        print(self._training_process[self._epochs-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; cost = 0.2325\n",
      "Iteration: 20 ; cost = 0.1616\n",
      "Iteration: 30 ; cost = 0.1236\n",
      "Iteration: 40 ; cost = 0.1000\n",
      "Iteration: 50 ; cost = 0.0830\n",
      "Iteration: 60 ; cost = 0.0698\n",
      "Iteration: 70 ; cost = 0.0591\n",
      "Iteration: 80 ; cost = 0.0503\n",
      "Iteration: 90 ; cost = 0.0430\n",
      "Iteration: 100 ; cost = 0.0369\n",
      "Iteration: 110 ; cost = 0.0318\n",
      "Iteration: 120 ; cost = 0.0275\n",
      "Iteration: 130 ; cost = 0.0239\n",
      "Iteration: 140 ; cost = 0.0208\n",
      "Iteration: 150 ; cost = 0.0182\n",
      "Iteration: 160 ; cost = 0.0160\n",
      "Iteration: 170 ; cost = 0.0142\n",
      "Iteration: 180 ; cost = 0.0126\n",
      "Iteration: 190 ; cost = 0.0112\n",
      "Iteration: 200 ; cost = 0.0101\n",
      "Iteration: 210 ; cost = 0.0091\n",
      "Iteration: 220 ; cost = 0.0083\n",
      "Iteration: 230 ; cost = 0.0076\n",
      "Iteration: 240 ; cost = 0.0070\n",
      "Iteration: 250 ; cost = 0.0065\n",
      "Iteration: 260 ; cost = 0.0060\n",
      "Iteration: 270 ; cost = 0.0056\n",
      "Iteration: 280 ; cost = 0.0053\n",
      "Iteration: 290 ; cost = 0.0050\n",
      "Iteration: 300 ; cost = 0.0048\n",
      "User Latent P:\n",
      "[[ 0.24752074  0.29420478 -1.54026316]\n",
      " [-0.99481879 -0.3696489  -1.09012896]\n",
      " [ 0.97373426 -0.49114635  0.85061049]\n",
      " [ 0.193284   -1.46208417  0.09464522]\n",
      " [-0.1785077  -0.76831015  0.49409089]\n",
      " [-1.26810632  0.62411054  0.70759263]\n",
      " [ 0.04010167 -1.77112001 -0.44231535]]\n",
      "Item Latent Q:\n",
      "[[-1.36248383  0.95555514 -0.39332231  0.28967556  1.46531005]\n",
      " [ 1.12194866  1.11601283 -0.24628665  0.14546497 -0.15712722]\n",
      " [ 0.28959192 -1.62700543  0.65924358  1.09944108 -0.37854552]]\n",
      "P x Q:\n",
      "[[-0.45320811  3.07087254 -1.18522273 -1.5789314   0.89952677]\n",
      " [ 0.62500488  0.4105086  -0.2363365  -1.54047821 -0.98697262]\n",
      " [-1.63140825 -1.00161673  0.29873089  1.14581854  1.18200026]\n",
      " [-1.8763212  -1.60099945  0.34646316 -0.05263553  0.47712667]\n",
      " [-0.47570597 -1.83190649  0.58516184  0.37975229 -0.32788258]\n",
      " [ 2.63290745 -1.6664872   0.8115403   0.50140322 -2.22408971]\n",
      " [-2.16983456 -1.21862382  0.12883679 -0.73231911  0.50448903]]\n",
      "bias:\n",
      "2.590909090909091\n",
      "User Latent bias:\n",
      "[-0.44926988 -0.51998501  0.75271124  0.98327328  0.58878131  0.42905523\n",
      " -1.31315132]\n",
      "Item Latent bias:\n",
      "[-0.68745633 -0.34108013  1.17540065  0.46509376 -0.05959142]\n",
      "Final R matrix:\n",
      "[[ 1.00097477  4.87143161  2.13181713  1.02780157  2.98157455]\n",
      " [ 2.00847264  2.14035255  3.00998823  0.99553963  1.02436003]\n",
      " [ 1.02475576  2.00092347  4.81775186  4.95453263  4.46602916]\n",
      " [ 1.01040484  1.63210279  5.09604618  3.9866406   3.99171763]\n",
      " [ 2.01652811  1.00670378  4.94025289  4.02453645  2.7922164 ]\n",
      " [ 4.96541544  1.01239699  5.00690527  3.98646129  0.73628319]\n",
      " [-1.57953311 -0.28194617  2.58199521  1.01053242  1.72265539]]\n",
      "Final RMSE:\n",
      "0.004792406853792505\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # rating matrix - User X Item : (7 X 5)\n",
    "    R = np.array([\n",
    "        [1, 0, 0, 1, 3],\n",
    "        [2, 0, 3, 1, 1],\n",
    "        [1, 2, 0, 5, 0],\n",
    "        [1, 0, 0, 4, 4],\n",
    "        [2, 1, 5, 4, 0],\n",
    "        [5, 1, 5, 4, 0],\n",
    "        [0, 0, 0, 1, 0],\n",
    "    ])\n",
    "\n",
    "    # P, Q is (7 X k), (k X 5) matrix\n",
    "    # 데이터 값이 작아 k = 3을 썼지만 보통 인자값으로는 20을 많이 사용한다.\n",
    "    factorizer = MatrixFactorization(R, k=3, learning_rate=0.01, reg_param=0.01, epochs=300, verbose=True)\n",
    "    factorizer.fit()\n",
    "    factorizer.print_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
